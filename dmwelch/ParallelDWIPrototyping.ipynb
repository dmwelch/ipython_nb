{
 "metadata": {
  "name": "ParallelDWIPrototyping"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Purpose\n",
      "=======\n",
      "\n",
      "The purpose of this pipeline is to complete all the pre-processing steps needed to turn diffusion-weighted images into FA images that will be used to build a template diffusion tensor atlas for fiber tracking.\n",
      "\n",
      "Inputs\n",
      "======\n",
      "The input to this pipeline is a list of subject IDs that is used to generate lists of the corresponding DWIs processed with automated quality control, T2s, and brain label images that are treated as brain masks.\n",
      "\n",
      "Pipeline Steps for CreateDWIWorkflow\n",
      "====================================\n",
      "1. A rigid transform from the b0 of the DWI to the T2 is first derived with BRAINSFit. This rigid transform is then used to resample the DWI in place into the physical space of the T2 (with gtractResampleDWIInPlace) while preserving the voxel lattice of the DWI.\n",
      "\n",
      "1. The b0 from the DWI resampled in place is extracted with extractNrrdVectorIndex. A BSpline transform from the T2 to the b0 of the DWI resampled in place is then derived with BRAINSFit and used to resample the brain mask into the the space of the DWI resampled in place with BRAINSResample.\n",
      "\n",
      "1. A masked tensor image is estimated with dtiprocess using the DWI resampled in place and resampled brain mask. dtiprocess is used again to compute FA, MD, RD, Frobenius norm, lambda1 (AD), lambda2, and lambda3 images with the masked tensor image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import glob\n",
      "import sys\n",
      "\n",
      "#\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\n",
      "#####################################################################################\n",
      "#     Prepend the shell environment search paths\n",
      "PROGRAM_PATHS = '/raid0/homes/johnsonhj/src/BSA-clang31/bin'\n",
      "PROGRAM_PATHS = PROGRAM_PATHS.split(':')\n",
      "PROGRAM_PATHS.extend(os.environ['PATH'].split(':'))\n",
      "os.environ['PATH'] = ':'.join(PROGRAM_PATHS)\n",
      "\n",
      "CUSTOM_ENVIRONMENT=dict()\n",
      "    \n",
      "CLUSTER_QUEUE_LONG = '-q OSX'\n",
      "CLUSTER_QUEUE= '-q OSX'\n",
      "    \n",
      "\n",
      "    \n",
      "# Platform specific information\n",
      "#     Prepend the python search paths\n",
      "PYTHON_AUX_PATHS = '/raid0/homes/johnsonhj/src/BRAINSStandAlone/AutoWorkup:/raid0/homes/johnsonhj/src/BSA-clang31/SimpleITK-build/XXXWrapping/:/raid0/homes/johnsonhj/src/BSA-clang31/NIPYPE'\n",
      "PYTHON_AUX_PATHS = PYTHON_AUX_PATHS.split(':')\n",
      "PYTHON_AUX_PATHS.extend(sys.path)\n",
      "sys.path = PYTHON_AUX_PATHS\n",
      "\n",
      "import SimpleITK as sitk\n",
      "import nipype\n",
      "from nipype.interfaces.base import CommandLine, CommandLineInputSpec, TraitedSpec, File, Directory\n",
      "from nipype.interfaces.base import traits, isdefined, BaseInterface\n",
      "from nipype.interfaces.utility import Merge, Split, Function, Rename, IdentityInterface\n",
      "import nipype.interfaces.io as nio   # Data i/oS\n",
      "import nipype.pipeline.engine as pe  # pypeline engine\n",
      "from nipype.interfaces.freesurfer import ReconAll\n",
      "from SEMTools import *\n",
      "\n",
      "def get_global_sge_script(pythonPathsList, binPathsList, customEnvironment={}):\n",
      "    \"\"\"This is a wrapper script for running commands on an SGE cluster\n",
      "so that all the python modules and commands are pathed properly\"\"\"\n",
      "\n",
      "    custEnvString = \"\"\n",
      "    for key, value in customEnvironment.items():\n",
      "        custEnvString += \"export \" + key + \"=\" + value + \"\\n\"\n",
      "\n",
      "    PYTHONPATH = \":\".join(pythonPathsList)\n",
      "    BASE_BUILDS = \":\".join(binPathsList)\n",
      "    GLOBAL_SGE_SCRIPT = \"\"\"#!/bin/bash\n",
      "echo \"STARTED at: $(date +'%F-%T')\"\n",
      "echo \"Ran on: $(hostname)\"\n",
      "export PATH={BINPATH}\n",
      "export PYTHONPATH={PYTHONPATH}\n",
      "\n",
      "echo \"========= CUSTOM ENVIORNMENT SETTINGS ==========\"\n",
      "echo \"export PYTHONPATH={PYTHONPATH}\"\n",
      "echo \"export PATH={BINPATH}\"\n",
      "echo \"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\"\n",
      "\n",
      "echo \"With custom environment:\"\n",
      "echo {CUSTENV}\n",
      "{CUSTENV}\n",
      "## NOTE:  nipype inserts the actual commands that need running below this section.\n",
      "\"\"\".format(PYTHONPATH=PYTHONPATH, BINPATH=BASE_BUILDS, CUSTENV=custEnvString)\n",
      "    return GLOBAL_SGE_SCRIPT\n",
      "\n",
      "## Create the shell wrapper script for ensuring that all jobs running on remote hosts from SGE\n",
      "#  have the same environment as the job submission host.\n",
      "JOB_SCRIPT = get_global_sge_script(sys.path, PROGRAM_PATHS, CUSTOM_ENVIRONMENT)\n",
      "SGE_JOB_SCRIPT=JOB_SCRIPT\n",
      "\n",
      "def GetDWIReferenceImagesFromSessionID(SESSION_TUPLE,BASE_STRUCT,BASE_DWI):\n",
      "    \"\"\"A function to extract file names from base parameters\"\"\"\n",
      "    import os\n",
      "    import glob\n",
      "    PROJ_ID=SESSION_TUPLE[0]\n",
      "    SUBJ_ID=SESSION_TUPLE[1]\n",
      "    SESSION_ID=SESSION_TUPLE[2]\n",
      "    FixImageList=glob.glob(\"{BASE_STRUCT}/{PROJ_ID}/{SUBJ_ID}/{SESSION_ID}/TissueClassify/t2_average_BRAINSABC.nii.gz\".format(BASE_STRUCT=BASE_STRUCT,PROJ_ID=PROJ_ID,SUBJ_ID=SUBJ_ID,SESSION_ID=SESSION_ID))\n",
      "    FixMaskImageList=glob.glob(\"{BASE_STRUCT}/{PROJ_ID}/{SUBJ_ID}/{SESSION_ID}/TissueClassify/fixed_brainlabels_seg.nii.gz\".format(BASE_STRUCT=BASE_STRUCT,PROJ_ID=PROJ_ID,SUBJ_ID=SUBJ_ID,SESSION_ID=SESSION_ID))\n",
      "    MovingDWIList=glob.glob(\"{BASE_DWI}/{PROJ_ID}/{SUBJ_ID}/{SESSION_ID}/*_concat_QCed.nrrd\".format(BASE_DWI=BASE_DWI,PROJ_ID=PROJ_ID,SUBJ_ID=SUBJ_ID,SESSION_ID=SESSION_ID))\n",
      "    \n",
      "    ## Should check that each list has 1 element\n",
      "    \n",
      "    print \"^\"*80\n",
      "    print SESSION_TUPLE\n",
      "    print BASE_STRUCT\n",
      "    print BASE_DWI\n",
      "    print \"^\"*80\n",
      "    print FixImageList\n",
      "    print FixMaskImageList\n",
      "    print MovingDWIList\n",
      "    print \"^\"*80\n",
      "    FixImage=FixImageList[0]\n",
      "    FixMaskImage=FixMaskImageList[0]\n",
      "    MovingDWI=MovingDWIList[0]\n",
      "    \n",
      "\n",
      "    print \"=\"*80\n",
      "    print FixImage\n",
      "    print FixMaskImage\n",
      "    print MovingDWI\n",
      "    print \"=\"*80\n",
      "    \n",
      "    return FixImage,FixMaskImage,MovingDWI\n",
      "\n",
      "\n",
      "def MergeByExtendListElements(FAImageList):\n",
      "    ## Initial list with empty dictionaries\n",
      "    ListOfImagesDictionaries=list()\n",
      "    for ff in FAImageList:\n",
      "        ListOfImagesDictionaries.append( { 'FA': ff, 'DUMMY': ff } )\n",
      "\n",
      "    ## HACK:  Need to make it so that AVG_AIR.nii.gz is has a background value of 1\n",
      "    registrationImageTypes = ['FA']  # ['T1','T2'] someday.\n",
      "    # DefaultContinuousInterpolationType='LanczosWindowedSinc' ## Could also be Linear for speed.\n",
      "    DefaultContinuousInterpolationType = 'Linear'\n",
      "    interpolationMapping = {'T1': DefaultContinuousInterpolationType,\n",
      "                            'T2': DefaultContinuousInterpolationType,\n",
      "                            'PD': DefaultContinuousInterpolationType,\n",
      "                            'FL': DefaultContinuousInterpolationType,\n",
      "                            'FA': DefaultContinuousInterpolationType,\n",
      "                            'DUMMY': DefaultContinuousInterpolationType,\n",
      "                            'BRAINMASK': 'MultiLabel'}\n",
      "    return ListOfImagesDictionaries,registrationImageTypes,interpolationMapping\n",
      "\n",
      "\n",
      "def CreateDWIWorkFlow(proj_name,subj_name,session_name):  \n",
      "    WFname=\"DWIPrototype_\"+str(proj_name)+str(subj_name)+\"_\"+str(session_name)\n",
      "    DWIWorkflow = pe.Workflow(name=WFname)\n",
      "    #DWIWorkflow.base_dir = os.path.join(CACHE_BASE,session_name)\n",
      "    \n",
      "    inputsSpec = pe.MapNode(interface=IdentityInterface(fields=['T2Volume', 'DWIVolume','BrainMask']),\n",
      "                                                        iterfield=['T2Volume', 'DWIVolume','BrainMask'],\n",
      "                                                        name='inputspec')\n",
      "    \n",
      "    outputsSpec = pe.MapNode(interface=IdentityInterface(fields=['FAImage','MDImage','RDImage','FrobeniusNormImage','Lambda1Image','Lambda2Image','Lambda3Image']),\n",
      "                                                         iterfield=['FAImage','MDImage','RDImage','FrobeniusNormImage','Lambda1Image','Lambda2Image','Lambda3Image'],\n",
      "                                                         name='outputspec')\n",
      "    \n",
      "    BFitB0_T2 = pe.MapNode(interface=BRAINSFit(), iterfield=['fixedVolume','movingVolume'],name=\"B0ToT2_Rigid\")\n",
      "    #BF_cpu_sge_options_dictionary = {'qsub_args': '-S /bin/bash -pe smp1 2-12 -l h_vmem=14G,mem_free=4G -o /dev/null -e /dev/null ' + CLUSTER_QUEUE, 'overwrite': True}\n",
      "    \n",
      "    #BFitB0_T2.plugin_args = BF_cpu_sge_options_dictionary\n",
      "    BFitB0_T2.inputs.costMetric = \"MMI\"\n",
      "    BFitB0_T2.inputs.numberOfSamples = 100000\n",
      "    BFitB0_T2.inputs.numberOfIterations = [1500]\n",
      "    BFitB0_T2.inputs.numberOfHistogramBins = 50\n",
      "    BFitB0_T2.inputs.maximumStepLength = 0.2\n",
      "    BFitB0_T2.inputs.minimumStepLength = [0.00005]\n",
      "    BFitB0_T2.inputs.useRigid = True\n",
      "    #BFitB0_T2.inputs.useAffine = True  # Using initial transform from BRAINSABC\n",
      "    BFitB0_T2.inputs.maskInferiorCutOffFromCenter = 65\n",
      "    BFitB0_T2.inputs.maskProcessingMode = \"ROIAUTO\"\n",
      "    BFitB0_T2.inputs.ROIAutoDilateSize = 13\n",
      "    BFitB0_T2.inputs.backgroundFillValue = 0.0\n",
      "    BFitB0_T2.inputs.initializeTransformMode = 'useCenterOfHeadAlign'\n",
      "    \n",
      "    BFitB0_T2.inputs.outputTransform = \"B0ToT2_RigidTransform.h5\"\n",
      "    BFitB0_T2.inputs.outputVolume = \"B0_in_T2Space_Output.nii.gz\"\n",
      "    \n",
      "    DWIWorkflow.connect(inputsSpec, 'T2Volume', BFitB0_T2, 'fixedVolume')\n",
      "    DWIWorkflow.connect(inputsSpec, 'DWIVolume', BFitB0_T2, 'movingVolume')\n",
      "    \n",
      "    DWIRIP = pe.MapNode(interface=gtractResampleDWIInPlace(),\n",
      "                        iterfield=['inputTransform','inputVolume'],\n",
      "                        name=\"DWIRIP_B0ToT2\")\n",
      "    DWIRIP.inputs.outputVolume = 'DTIPRepOutput_RIP.nrrd'\n",
      "    #DWIRIP.inputs.imageOutputSize = [164,164,100]\n",
      "    \n",
      "    DWIWorkflow.connect(BFitB0_T2,'outputTransform',DWIRIP,'inputTransform')\n",
      "    DWIWorkflow.connect(inputsSpec, 'DWIVolume',DWIRIP,'inputVolume')\n",
      "    \n",
      "    BSPLINE_T2_TO_RIPB0 = pe.MapNode(interface=BRAINSFit(), iterfield=['fixedVolume','movingVolume'],name=\"BSPLINE_T2_TO_RIPB0\")\n",
      "    #BSPLINE_T2_TO_RIPB0.plugin_args = BF_cpu_sge_options_dictionary\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.costMetric = \"MMI\"\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.numberOfSamples = 100000\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.numberOfIterations = [1500]\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.numberOfHistogramBins = 50\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.maximumStepLength = 0.2\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.minimumStepLength = [0.00025,0.00025,0.00025,0.00025,0.00025]\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useRigid = True\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useScaleVersor3D = True\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useScaleSkewVersor3D = True\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useAffine = True  # Using initial transform from BRAINSABC\n",
      "    \n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useBSpline = True\n",
      "    #BSPLINE_T2_TO_RIPB0.inputs.useROIBSpline = True\n",
      "    \n",
      "    ##  This needs to be debugged, it should work. BSPLINE_T2_TO_RIPB0.inputs.useROIBSpline = True\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useExplicitPDFDerivativesMode = \"AUTO\"\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.useCachingOfBSplineWeightsMode = \"ON\"\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.maxBSplineDisplacement = 24\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.splineGridSize = [ 14, 10, 12 ]\n",
      "    \n",
      "    BSPLINE_T2_TO_RIPB0.inputs.maskInferiorCutOffFromCenter = 65\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.maskProcessingMode = \"ROIAUTO\"\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.ROIAutoDilateSize = 13\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.backgroundFillValue = 0.0\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.initializeTransformMode = 'useCenterOfHeadAlign'\n",
      "    \n",
      "    \n",
      "    BSPLINE_T2_TO_RIPB0.inputs.bsplineTransform = \"T2ToRIPB0_BSplineTransform.h5\"\n",
      "    BSPLINE_T2_TO_RIPB0.inputs.outputVolume = \"T2ToRIPB0_Output.nii.gz\"\n",
      "    \n",
      "    DWIWorkflow.connect(DWIRIP, 'outputVolume', BSPLINE_T2_TO_RIPB0, 'fixedVolume')\n",
      "    DWIWorkflow.connect(inputsSpec, 'T2Volume', BSPLINE_T2_TO_RIPB0, 'movingVolume')\n",
      "    \n",
      "    EXTRACT_B0 = pe.MapNode(interface=extractNrrdVectorIndex(),iterfield=['inputVolume'],name=\"EXTRACT_B0\")\n",
      "    EXTRACT_B0.inputs.vectorIndex = 0\n",
      "    EXTRACT_B0.inputs.outputVolume = 'B0_Image.nrrd'\n",
      "    DWIWorkflow.connect(DWIRIP,'outputVolume',EXTRACT_B0,'inputVolume')\n",
      "    \n",
      "    RESAMPLE_BRAINMASK = pe.MapNode(interface=BRAINSResample(),iterfield=['warpTransform','inputVolume','referenceVolume'], name=\"RESAMPLE_BRAINMASK\")\n",
      "    RESAMPLE_BRAINMASK.inputs.interpolationMode = 'NearestNeighbor' # This needs to be debugged'Binary'\n",
      "    RESAMPLE_BRAINMASK.inputs.outputVolume = 'DeformedBrainMaskDWIRIP.nrrd'\n",
      "    RESAMPLE_BRAINMASK.inputs.pixelType = 'uchar'\n",
      "    \n",
      "    DWIWorkflow.connect(BSPLINE_T2_TO_RIPB0,'bsplineTransform',RESAMPLE_BRAINMASK,'warpTransform')\n",
      "    DWIWorkflow.connect(inputsSpec, 'BrainMask',RESAMPLE_BRAINMASK,'inputVolume')\n",
      "    DWIWorkflow.connect(EXTRACT_B0,'outputVolume',RESAMPLE_BRAINMASK,'referenceVolume')\n",
      "    \n",
      "    DTIEstim = pe.MapNode(interface=dtiestim(),iterfield=['dwi_image','brain_mask'], name=\"DTIEstim_Process\")\n",
      "    DTIEstim.inputs.method = \"wls\"\n",
      "    DTIEstim.inputs.tensor_output = 'DTI_Output.nrrd'\n",
      "    DWIWorkflow.connect(DWIRIP, 'outputVolume', DTIEstim, 'dwi_image')\n",
      "    DWIWorkflow.connect(RESAMPLE_BRAINMASK, 'outputVolume', DTIEstim, 'brain_mask')\n",
      "    \n",
      "    DTIProcess = pe.MapNode(interface=dtiprocess(),iterfield=['dti_image'], name=\"DTIProcess\")\n",
      "    DTIProcess.inputs.fa_output = \"FA.nrrd\"\n",
      "    DTIProcess.inputs.md_output = \"MD.nrrd\"\n",
      "    DTIProcess.inputs.RD_output = \"RD.nrrd\"\n",
      "    DTIProcess.inputs.frobenius_norm_output = \"frobenius_norm_output.nrrd\"\n",
      "    DTIProcess.inputs.lambda1_output = \"lambda1_output.nrrd\"\n",
      "    DTIProcess.inputs.lambda2_output = \"lambda2_output.nrrd\"\n",
      "    DTIProcess.inputs.lambda3_output = \"lambda3_output.nrrd\"\n",
      "    DTIProcess.inputs.scalar_float = True\n",
      "    \n",
      "    DWIWorkflow.connect(DTIEstim,'tensor_output',DTIProcess,'dti_image')\n",
      "    DWIWorkflow.connect(DTIProcess,'fa_output',outputsSpec,'FAImage')\n",
      "    DWIWorkflow.connect(DTIProcess,'md_output',outputsSpec,'MDImage')\n",
      "    DWIWorkflow.connect(DTIProcess,'RD_output',outputsSpec,'RDImage')\n",
      "    DWIWorkflow.connect(DTIProcess,'frobenius_norm_output',outputsSpec,'FrobeniusNormImage')\n",
      "    DWIWorkflow.connect(DTIProcess,'lambda1_output',outputsSpec,'Lambda1Image')\n",
      "    DWIWorkflow.connect(DTIProcess,'lambda2_output',outputsSpec,'Lambda2Image')\n",
      "    DWIWorkflow.connect(DTIProcess,'lambda3_output',outputsSpec,'Lambda3Image')\n",
      "\n",
      "    return DWIWorkflow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## This cell is to  provide information specific to the subjects that need to be processed in our lab.\n",
      "SESSIONS_TO_PROCESS=[('PHD_024','0003','42245'),('PHD_024','0005','33071'),('PHD_024','0029','84091'),\n",
      "                     ('PHD_024','0091','60387'),('PHD_024','0091','78867'),('PHD_024','0093','50120'),\n",
      "                     ('PHD_024','0093','60307'),('PHD_024','0093','88775'),('PHD_024','0122','42742'),\n",
      "                     ('PHD_024','0122','63892'),('PHD_024','0131','76658'),('PHD_024','0131','90863'),\n",
      "                     ('PHD_024','0132','38235'),('PHD_024','0132','43991'),('PHD_024','0132','74443'),\n",
      "                     ('PHD_024','0133','63793'),('PHD_024','0133','81826'),('PHD_024','0137','11834'),\n",
      "                     ('PHD_024','0138','84460'),('PHD_024','0140','31352')]\n",
      "BASE_STRUCT = '/paulsen/Experiments/20130202_PREDICTHD_Results'\n",
      "BASE_DWI ='/paulsen/Experiments/20130211_DWICONCAT'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The desired behavior would be to use a MapNode here"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MasterWFname=\"ManySubjectDWIPrototype\"\n",
      "MasterDWIWorkflow = pe.Workflow(name=MasterWFname)\n",
      "\n",
      "BASE_DIR = os.path.join('/hjohnson/HDNI/20130214_DWIPROCESSING_NIPYPE/DWI_CACHE/JOY_PARALLEL',\"MasterWFname\")\n",
      "MasterDWIWorkflow.base_dir = BASE_DIR\n",
      "\n",
      "MasterDWIWorkflow.config['execution'] = {\n",
      "        'plugin': 'Linear',\n",
      "        #'stop_on_first_crash':'true',\n",
      "        #'stop_on_first_rerun': 'true',\n",
      "        'stop_on_first_crash': 'false',\n",
      "        'stop_on_first_rerun': 'false',  # This stops at first attempt to rerun, before running, and before deleting previous results.\n",
      "        'hash_method': 'timestamp',\n",
      "        'single_thread_matlab': 'true',  # Multi-core 2011a  multi-core for matrix multiplication.\n",
      "        'remove_unnecessary_outputs': 'false',\n",
      "        'use_relative_paths': 'false',  # relative paths should be on, require hash update when changed.\n",
      "        'remove_node_directories': 'false',  # Experimental\n",
      "        'local_hash_check': 'true',\n",
      "        'job_finished_timeout': 45\n",
      "    }\n",
      "MasterDWIWorkflow.config['logging'] = {\n",
      "        'workflow_level': 'DEBUG',\n",
      "        'filemanip_level': 'DEBUG',\n",
      "        'interface_level': 'DEBUG',\n",
      "        'log_directory': BASE_DIR\n",
      "    }\n",
      "\n",
      "\n",
      "if True:\n",
      "    ## I can't figure out how to make this map node work, so resorting to a stupid for loop\n",
      "    GetFileNamesNode = pe.MapNode(interface=Function(function=GetDWIReferenceImagesFromSessionID,\n",
      "                            input_names=['SESSION_TUPLE','BASE_STRUCT','BASE_DWI'],\n",
      "                            output_names=['FixImage','FixMaskImage','MovingDWI']),\n",
      "                            iterfield = ['SESSION_TUPLE'],\n",
      "                            run_without_submitting=True, name=\"99_GetDWIReferenceImagesFromSessionID\")\n",
      "\n",
      "    GetFileNamesNode.inputs.SESSION_TUPLE=SESSIONS_TO_PROCESS\n",
      "    GetFileNamesNode.inputs.BASE_STRUCT = BASE_STRUCT\n",
      "    GetFileNamesNode.inputs.BASE_DWI = BASE_DWI\n",
      "\n",
      "    #ID_interface =  pe.Node(interface=IdentityInterface(fields=['T2Volume', 'DWIVolume','BrainMask'],\n",
      "    #                    iterfield=['T2Volume', 'DWIVolume','BrainMask']),\n",
      "    #                    name='ID_interface')\n",
      "    #MasterDWIWorkflow.connect(GetFileNamesNode,'FixImage',ID_interface,'T2Volume')\n",
      "    #MasterDWIWorkflow.connect(GetFileNamesNode,'FixMaskImage',ID_interface,'BrainMask')\n",
      "    #MasterDWIWorkflow.connect(GetFileNamesNode,'MovingDWI',ID_interface,'DWIVolume')\n",
      "\n",
      "    myDWIWorkflow = CreateDWIWorkFlow(\"ALL_PROJ\",\"ALL_SUBJ\",\"ALL_SESSION\")\n",
      "    MasterDWIWorkflow.connect(GetFileNamesNode,'FixImage',myDWIWorkflow,'inputspec.T2Volume')\n",
      "    MasterDWIWorkflow.connect(GetFileNamesNode,'FixMaskImage',myDWIWorkflow,'inputspec.BrainMask')\n",
      "    MasterDWIWorkflow.connect(GetFileNamesNode,'MovingDWI',myDWIWorkflow,'inputspec.DWIVolume')\n",
      "    \"\"\"\n",
      "else:\n",
      "    all_workflows = dict()\n",
      "    GetFileNamesNode =dict()\n",
      "    \n",
      "    length_of_sessions = len(SESSIONS_TO_PROCESS)\n",
      "    MergeFAsNode = pe.Node(interface=Merge( length_of_sessions ),\n",
      "                           run_without_submitting=True,\n",
      "                           name=\"MergeFAsNode\")\n",
      "    index = 1\n",
      "    for singleSession in SESSIONS_TO_PROCESS:\n",
      "        localProjectID=singleSession[0]\n",
      "        localSubjectID=singleSession[1]\n",
      "        localSessionID=singleSession[2]\n",
      "        all_workflows[localSessionID] = CreateDWIWorkFlow(localProjectID,localSubjectID,localSessionID)\n",
      "        GetFileNamesNodeName='99_GetDWIReferenceImagesFromSessionID_'+str(localSessionID)\n",
      "        GetFileNamesNode[localSessionID] = pe.Node(interface=Function(function=GetDWIReferenceImagesFromSessionID,\n",
      "                            input_names=['SESSION_TUPLE','BASE_STRUCT','BASE_DWI'],\n",
      "                            output_names=['FixImage','FixMaskImage','MovingDWI']),\n",
      "                            run_without_submitting=True, name=GetFileNamesNodeName)\n",
      "        GetFileNamesNode[localSessionID].inputs.SESSION_TUPLE = singleSession\n",
      "        GetFileNamesNode[localSessionID].inputs.BASE_STRUCT = BASE_STRUCT\n",
      "        GetFileNamesNode[localSessionID].inputs.BASE_DWI = BASE_DWI\n",
      "        \n",
      "        MasterDWIWorkflow.connect(GetFileNamesNode[localSessionID],'FixImage',all_workflows[localSessionID],'inputspec.T2Volume')\n",
      "        MasterDWIWorkflow.connect(GetFileNamesNode[localSessionID],'FixMaskImage',all_workflows[localSessionID],'inputspec.BrainMask')\n",
      "        MasterDWIWorkflow.connect(GetFileNamesNode[localSessionID],'MovingDWI',all_workflows[localSessionID],'inputspec.DWIVolume')\n",
      "        \n",
      "        currentIn='in'+str(index)\n",
      "        index += 1\n",
      "        MasterDWIWorkflow.connect(all_workflows[localSessionID],'outputspec.FAImage',MergeFAsNode,currentIn)\n",
      "       \"\"\" \n",
      "   \n",
      "    ## Now do template building with FA's\n",
      "    import nipype.interfaces.ants as ants\n",
      "    \n",
      "    initAvg = pe.Node(interface=ants.AverageImages(), name ='initAvg')\n",
      "    initAvg.inputs.dimension = 3\n",
      "    initAvg.inputs.normalize = True\n",
      "    MasterDWIWorkflow.connect(myDWIWorkflow, \"outputspec.FAImage\", initAvg, \"images\")\n",
      "    \n",
      "    MergeByExtendListElementsNode = pe.Node(interface=Function(function = MergeByExtendListElements, input_names=['FAImageList'],\n",
      "                                                    output_names=['ListOfImagesDictionaries', 'registrationImageTypes', 'interpolationMapping']),\n",
      "                                                    run_without_submitting=True, name=\"99_FAMergeByExtendListElements\")\n",
      "    \n",
      "    MasterDWIWorkflow.connect(myDWIWorkflow, \"outputspec.FAImage\", MergeByExtendListElementsNode,'FAImageList')\n",
      "    ### USE ANTS REGISTRATION\n",
      "    # from nipype.workflows.smri.ants import antsRegistrationTemplateBuildSingleIterationWF\n",
      "    from BAWantsRegistrationBuildTemplate import BAWantsRegistrationTemplateBuildSingleIterationWF\n",
      "    buildTemplateIteration1 = BAWantsRegistrationTemplateBuildSingleIterationWF('iteration01')\n",
      "    ## TODO:  Change these parameters\n",
      "    BeginANTS_iter1 = buildTemplateIteration1.get_node(\"BeginANTS\")\n",
      "    BeginANTS_iter1.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 4-8 -l mem_free=9000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE_LONG), 'overwrite': True}\n",
      "    wimtdeformed_iter1 = buildTemplateIteration1.get_node(\"wimtdeformed\")\n",
      "    wimtdeformed_iter1.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 1-2 -l mem_free=2000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE), 'overwrite': True}\n",
      "    AvgAffineTransform_iter1 = buildTemplateIteration1.get_node(\"AvgAffineTransform\")\n",
      "    AvgAffineTransform_iter1.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 1 -l mem_free=2000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE), 'overwrite': True}\n",
      "    wimtPassivedeformed_iter1 = buildTemplateIteration1.get_node(\"wimtPassivedeformed\")\n",
      "    wimtPassivedeformed_iter1.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 1-2 -l mem_free=2000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE), 'overwrite': True}\n",
      "\n",
      "    MasterDWIWorkflow.connect(initAvg, 'output_average_image', buildTemplateIteration1, 'inputspec.fixed_image')\n",
      "    MasterDWIWorkflow.connect(MergeByExtendListElementsNode, 'ListOfImagesDictionaries', buildTemplateIteration1, 'inputspec.ListOfImagesDictionaries')\n",
      "    MasterDWIWorkflow.connect(MergeByExtendListElementsNode, 'registrationImageTypes', buildTemplateIteration1, 'inputspec.registrationImageTypes')\n",
      "    MasterDWIWorkflow.connect(MergeByExtendListElementsNode, 'interpolationMapping', buildTemplateIteration1, 'inputspec.interpolationMapping')\n",
      "\n",
      "    buildTemplateIteration2 = buildTemplateIteration1.clone(name='buildTemplateIteration2')\n",
      "    buildTemplateIteration2 = BAWantsRegistrationTemplateBuildSingleIterationWF('Iteration02')\n",
      "    ## TODO:  Change these parameters\n",
      "    BeginANTS_iter2 = buildTemplateIteration2.get_node(\"BeginANTS\")\n",
      "    BeginANTS_iter2.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 4-8 -l mem_free=9000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE_LONG), 'overwrite': True}\n",
      "    wimtdeformed_iter2 = buildTemplateIteration2.get_node(\"wimtdeformed\")\n",
      "    wimtdeformed_iter2.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 1-2 -l mem_free=2000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE), 'overwrite': True}\n",
      "    AvgAffineTransform_iter2 = buildTemplateIteration2.get_node(\"AvgAffineTransform\")\n",
      "    AvgAffineTransform_iter2.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 1 -l mem_free=2000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE), 'overwrite': True}\n",
      "    wimtPassivedeformed_iter2 = buildTemplateIteration2.get_node(\"wimtPassivedeformed\")\n",
      "    wimtPassivedeformed_iter2.plugin_args = {'template': SGE_JOB_SCRIPT, 'qsub_args': '-S /bin/bash -cwd -pe smp1 1-2 -l mem_free=2000M -o /dev/null -e /dev/null {QUEUE_OPTIONS}'.format(QUEUE_OPTIONS=CLUSTER_QUEUE), 'overwrite': True}\n",
      "\n",
      "    MasterDWIWorkflow.connect(buildTemplateIteration1, 'outputspec.template', buildTemplateIteration2, 'inputspec.fixed_image')\n",
      "    MasterDWIWorkflow.connect(MergeByExtendListElementsNode, 'ListOfImagesDictionaries', buildTemplateIteration2, 'inputspec.ListOfImagesDictionaries')\n",
      "    MasterDWIWorkflow.connect(MergeByExtendListElementsNode, 'registrationImageTypes', buildTemplateIteration2, 'inputspec.registrationImageTypes')\n",
      "    MasterDWIWorkflow.connect(MergeByExtendListElementsNode, 'interpolationMapping', buildTemplateIteration2, 'inputspec.interpolationMapping')\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now Start Processing\n",
      "===================="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "total_CPUS = multiprocessing.cpu_count()\n",
      "NUMPARALLEL=1\n",
      "os.environ['NSLOTS'] = \"{0}\".format(total_CPUS / NUMPARALLEL)\n",
      "\n",
      "\n",
      "\n",
      "MasterDWIWorkflow.write_graph()\n",
      "\n",
      "SGEFlavor = 'SGE'\n",
      "\n",
      "if False:\n",
      "    MasterDWIWorkflow.run()\n",
      "else:\n",
      "    MasterDWIWorkflow.run(plugin=SGEFlavor,\n",
      "                      plugin_args=dict(template=JOB_SCRIPT,\n",
      "                      qsub_args=\"-S /bin/bash -cwd -pe smp1 1-12 -l h_vmem=19G,mem_free=2G -o /dev/null -e /dev/null \" + \"-q OSX\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sys.argv\n",
      "print sys.api_version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}