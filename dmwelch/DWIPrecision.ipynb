{
 "metadata": {
  "name": "DWIPrecision"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "DWI Precision Checking"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Purpose</h2>\n",
      "* * *\n",
      "<em>Verify that the changes made to DTIPrep that correct for precision 'chopping' have not affected the data that has already been quality reviewed</em>\n",
      "\n",
      "<h2>Methods</h2>\n",
      "* * *\n",
      "\n",
      "1. Write a python script to check the heading information for all the Nrrd files that have a QA review in our database\n",
      "2. Write an ITK tool \n",
      "    1. to read in the two files to be compared, \n",
      "    2. sets direction cosines, origin, and spacing to the identity matrix, and \n",
      "    3. rasters through all the voxels testing equality.  \n",
      "    4. If a voxel is unequal, return 1, else 0. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import psycopg2 as sql\n",
      "import ConfigParser as cp\n",
      "from warnings import warn\n",
      "import os\n",
      "\n",
      "class Database(object):\n",
      "    \"\"\" Connect to the Postgres database and prevent multiple user collisions\n",
      "        during simultaneous evaluations\n",
      "    \"\"\"\n",
      "    def __init__(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Class attributes needed for connecting to and interacting with the database\n",
      "\n",
      "        ------------------------\n",
      "        Arguments:\n",
      "        - `host`: The name of the host machine (default = 'localhost')\n",
      "        - `port`: The port number (default = 5432)\n",
      "        - `pguser`: The username to connect to the Postgres server with (default = 'postgres')\n",
      "        - `database`: The name of the database to connect to.  If omitted, it is the same as the `user`\n",
      "        - `password`: The password associated with the `user` on the Postgres server (default = 'postgres')\n",
      "        - `login`: The reviewer login ID (default = $USER)\n",
      "        - `arraySize`: The number of rows to return (default = 1)\n",
      "        - `imageTable`: The database table to query for records (default = None)\n",
      "        - `reviewTable`: The database table to update with reviews (default = None)\n",
      "        ------------------------\n",
      "\n",
      "        \"\"\"\n",
      "        validArgs = ('host', 'port', 'pguser', 'database', 'password',\n",
      "                     'login', 'arraySize', 'imageTable', 'reviewTable')\n",
      "        defaults = ('localhost', 5432, 'postgres', None, 'postgres',\n",
      "                    os.environ['USER'], 0, 'dwi_raw', 'dwi_raw_reviews')\n",
      "        self._testing = False\n",
      "        self._lines = None\n",
      "        self.rows = None\n",
      "        self.connection = None\n",
      "        self.cursor = None\n",
      "        self.reviewer_id = None\n",
      "        self.imageTable = None\n",
      "        self.reviewTable = None\n",
      "        argsList = list(args)\n",
      "        for key in validArgs:\n",
      "            if key in kwds.keys():\n",
      "                value = kwds[key]\n",
      "            elif len(argsList) != 0:\n",
      "                value =  argsList.pop(0)\n",
      "            else:\n",
      "                value = defaults[validArgs.index(key)]\n",
      "            setattr(self, key, value)\n",
      "        if self.database is None:\n",
      "            self.database = self.pguser\n",
      "        super(Database,self).__init__()\n",
      "        \n",
      "\n",
      "    def open(self):\n",
      "        \"\"\" Open the database and create a cursor \"\"\"\n",
      "        self.connection = sql.connect(host=self.host,\n",
      "                                      port=self.port,\n",
      "                                      database=self.database,\n",
      "                                      user=self.pguser,\n",
      "                                      password=self.password)\n",
      "        self.cursor = self.connection.cursor()\n",
      "        self.cursor.arraysize = self.arraySize\n",
      "\n",
      "\n",
      "    def close(self):\n",
      "        \"\"\" Close cursor and connection, setting values to None \"\"\"\n",
      "        self.cursor.close()\n",
      "        self.cursor = None\n",
      "        self.connection.close()\n",
      "        self.connection = None\n",
      "\n",
      "        \n",
      "    def getRecords(self, status='R', imageTable=None, **kwds):\n",
      "        \"\"\" Return a dictionary of rows where the number of rows == self.arraySize \"\"\"\n",
      "        if imageTable is None:\n",
      "            imageTable = self.imageTable\n",
      "        assert not imageTable is None, 'Table is not specified: value is \"None\"'\n",
      "        self.imageTable = imageTable\n",
      "        assert self.cursor is not None, 'The database is not open! Run Database.open()'\n",
      "        getRecord = \"SELECT * FROM {0} WHERE status = '{1}' ORDER BY priority\".format(imageTable, status)\n",
      "        try:\n",
      "            # logging.info(getRecord)\n",
      "            self.cursor.execute(getRecord)\n",
      "        except sql.ProgrammingError:\n",
      "            raise ValueError(\"The table '%s' does not exist in the database!\" % imageTable)\n",
      "        except sql.InternalError:\n",
      "            raise ValueError(\"The status '%s' is not a valid one\" % status)\n",
      "        except:\n",
      "            # logging.error()\n",
      "            print(\"SQL query: %s\" % getRecord)\n",
      "            raise\n",
      "        self.rows = self.cursor.fetchall()\n",
      "        if self.rows is None or self.rows == []:\n",
      "            # logging.warning()\n",
      "            print(\"No rows in table %s with status %s were found!\" % (imageTable, status))\n",
      "\n",
      "\n",
      "\n",
      "    def readRecords(self, **kwds):\n",
      "        \"\"\" Find a given number of records with status == 'R' and return the records in a dictionary-like object \"\"\"\n",
      "        self.open()\n",
      "        try:\n",
      "            if self._testing and 'imageTable' in kwds.keys():\n",
      "                self.imageTable = kwds['imageTable']\n",
      "            self.getRecords(**kwds)\n",
      "        finally:\n",
      "            self.close()\n",
      "        return self.rows\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import keyring\n",
      "db = Database(host='psych-db.psychiatry.uiowa.edu', database='AutoWorkUp', pguser='autoworkup', password=keyring.get_password('autoworkup', user))\n",
      "reviewedRecords = db.readRecords(status='R', imageTable='dwi_raw')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(reviewedRecords)\n",
      "# reviewedRecords[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "4634"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Check if all the records from the database exist..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oldcount = newcount = bothcount = 0\n",
      "for record_id, root, site, subject, session, dirname, filename, status, priority, _ in reviewedRecords:\n",
      "    if site[:4] == 'HDNI':\n",
      "        pass\n",
      "    else:\n",
      "        continue\n",
      "    newpath = os.path.join(root, site, subject, session, dirname, \"_\".join([subject, session, filename + \".nrrd\"]))\n",
      "    if not os.path.exists(newpath):\n",
      "        # DWI gradient number may have been incremented\n",
      "        prefix, numbers = filename.split('-')\n",
      "        gradient, series = numbers.split('_')\n",
      "        newgradient = str(int(gradient) + 1)\n",
      "        newfilename = prefix + \"-\" + newgradient + \"_\" + series\n",
      "        newpath = os.path.join(root, site, subject, session, dirname, \"_\".join([subject, session, newfilename + \".nrrd\"]))\n",
      "    \n",
      "    oldpath = os.path.join('/paulsen/20130131_BACKUP_TRUNCATED_DWI', site, subject, session, dirname, \"_\".join([subject, session, filename + \".nrrd\"]))\n",
      "    if not os.path.exists(oldpath) and not os.path.exists(newpath):\n",
      "        bothcount += 1\n",
      "        #print \"*\" * 50\n",
      "        #print \"Files could not be found:\"\n",
      "        #print oldpath\n",
      "        #print newpath\n",
      "    elif not os.path.exists(oldpath):\n",
      "        oldcount += 1\n",
      "        # print \"MISSING\"\n",
      "        # print \"Old: %s\" % oldpath\n",
      "        #break\n",
      "    elif not os.path.exists(newpath):\n",
      "        newcount += 1\n",
      "        # print \"MISSING\"\n",
      "        # print \"New: %s\" % newpath\n",
      "        #break\n",
      "print oldcount\n",
      "print newcount\n",
      "print bothcount"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1052\n",
        "0\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls /paulsen/MRx/PHD_001/2697/41305/ANONRAW/2697_41305_DWI-37_7.nrrd\n",
      "!ls /paulsen/20130131_BACKUP_TRUNCATED_DWI/PHD_001/2697/41305/ANONRAW/2697_41305_DWI-37_7.nrrd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ls: /paulsen/MRx/PHD_001/2697/41305/ANONRAW/2697_41305_DWI-37_7.nrrd: No such file or directory\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/paulsen/20130131_BACKUP_TRUNCATED_DWI/PHD_001/2697/41305/ANONRAW/2697_41305_DWI-37_7.nrrd\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Compare the headers... "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for record_id, root, site, subject, session, dirname, filename, status, priority, _ in reviewedRecords:\n",
      "    if site[:4] == 'HDNI':\n",
      "        pass\n",
      "    else:\n",
      "        newpath = os.path.join(root, site, subject, session, dirname, \"_\".join([subject, session, filename + \".nrrd\"]))\n",
      "        if not os.path.exists(newpath):\n",
      "            # DWI gradient number may have been incremented\n",
      "            prefix, numbers = filename.split('-')\n",
      "            gradient, series = numbers.split('_')\n",
      "            newgradient = str(int(gradient) + 1)\n",
      "            newfilename = prefix + \"-\" + newgradient + \"_\" + series\n",
      "            newpath = os.path.join(root, site, subject, session, dirname, \"_\".join([subject, session, newfilename + \".nrrd\"]))\n",
      "    \n",
      "        oldpath = os.path.join('/paulsen/20130131_BACKUP_TRUNCATED_DWI', site, subject, session, dirname, \"_\".join([subject, session, filename + \".nrrd\"]))\n",
      "\n",
      "        prefix, numbers = filename.split('-')\n",
      "        oldgradient, series = numbers.split('_')\n",
      "\n",
      "        # number of 'standard' lines in header\n",
      "        headerLines_old = headerLines_new = 16 \n",
      "        headerLines_old += int(oldgradient)\n",
      "        headerLines_new += int(newgradient)\n",
      "        \n",
      "        #HACK\n",
      "        #newpath = \"/paulsen/MRx/PHD_048/2408/16520/ANONRAW/2408_16520_DWI-34_801.nrrd\"\n",
      "        #headerLines_new = 34\n",
      "        #oldpath = \"/paulsen/20130131_BACKUP_TRUNCATED_DWI/PHD_048/2408/16520/ANONRAW/2408_16520_DWI-33_801.nrrd\"\n",
      "        #headerLines_old = 33\n",
      "\n",
      "        newpath = \"/paulsen/MRx/PHD_024/2576/27032/ANONRAW/2576_27032_DWI-65_5.nrrd\"\n",
      "        headerLines_new = 65\n",
      "        oldpath = \"/paulsen/20130131_BACKUP_TRUNCATED_DWI/PHD_024/2576/27032/ANONRAW/2576_27032_DWI-65_5.nrrd\"\n",
      "        headerLines_old = 65\n",
      "        #END HACK\n",
      "        \n",
      "        oldHeader = []\n",
      "        newHeader = []\n",
      "        if os.path.exists(oldpath) and os.path.exists(newpath):\n",
      "            with open(oldpath, 'r') as old:\n",
      "                for count in range(headerLines_old):\n",
      "                    oldHeader.append(old.readline())\n",
      "        \n",
      "            with open(newpath, 'r') as new:\n",
      "                for count in range(headerLines_new):\n",
      "                    newHeader.append(new.readline())\n",
      "            print oldpath\n",
      "            print newpath\n",
      "            break\n",
      "        else:\n",
      "            # print oldpath\n",
      "            # print newpath\n",
      "            pass\n",
      "# print oldHeader\n",
      "# print newHeader"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'reviewedRecords' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-d40308dd90df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrecord_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviewedRecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'HDNI'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".nrrd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'reviewedRecords' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "# HACK\n",
      "newpath = \"/ipldev/scratch/welchdm/f1.nrrd\"\n",
      "oldpath = \"/ipldev/scratch/welchdm/f2.nrrd\"\n",
      "headerLines_new = 30\n",
      "headerLines_old = 29\n",
      "# newpath = \"/paulsen/MRx/FMRI_HD_120/0097/71829/ANONRAW/0097_71829_DWI-79_24.nrrd\"\n",
      "# oldpath = \"/paulsen/20130131_BACKUP_TRUNCATED_DWI/FMRI_HD_120/0097/71829/ANONRAW/0097_71829_DWI-79_24.nrrd\"\n",
      "# headerLines_new = 79 + 16\n",
      "# headerLines_old = 79 + 16\n",
      "# END HACK\n",
      "oldHeader = []\n",
      "newHeader = []\n",
      "if os.path.exists(oldpath) and os.path.exists(newpath):\n",
      "    with open(oldpath, 'r') as old:\n",
      "        for count in range(headerLines_old):\n",
      "            oldHeader.append(old.readline())\n",
      "        \n",
      "    with open(newpath, 'r') as new:\n",
      "        for count in range(headerLines_new):\n",
      "            newHeader.append(new.readline())\n",
      "# print oldpath\n",
      "# print newpath\n",
      "#print oldHeader\n",
      "#print \"\\n\" * 5\n",
      "#print newHeader"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Functions to compare headers..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def compareLine0(oldHeader, newHeader):\n",
      "    #line 0\n",
      "    valueOld = re.search(r'NRRD(?P<val>[0-9]{4})$', oldHeader[0]).group('val')\n",
      "    valueNew = re.search(r'NRRD(?P<val>[0-9]{4})$', newHeader[0]).group('val')\n",
      "    if valueOld != valueNew:\n",
      "        return False\n",
      "    return True\n",
      "\n",
      "# line 1\n",
      "# _, valueOld = re.split(\"\\s*\", oldHeader[1][:-1])\n",
      "# _, valueNew = re.split(\"\\s*\", newHeader[1][:-1])\n",
      "# print valueOld == valueNew\n",
      "\n",
      "\n",
      "def compareLine2(oldHeader, newHeader):\n",
      "    #line 2\n",
      "    _, valueOld = re.split(\"\\s*\", oldHeader[2][:-1])\n",
      "    _, valueNew = re.split(\"\\s*\", newHeader[2][:-1])\n",
      "    if int(valueOld) != int(valueNew):\n",
      "        return False\n",
      "    return True\n",
      "\n",
      "#line 3\n",
      "# _, valueOld = re.split(\"\\s*\", oldHeader[3][:-1])\n",
      "# _, valueNew = re.split(\"\\s*\", newHeader[3][:-1])\n",
      "# print str(valueOld) == str(valueNew)\n",
      "\n",
      "\n",
      "def compareLine4(oldHeader, newHeader):\n",
      "    #line 4\n",
      "    valueOld = re.split(\"\\s*\", oldHeader[4][:-1])\n",
      "    valueNew = re.split(\"\\s*\", newHeader[4][:-1])\n",
      "    oldInts = map(int, valueOld[1:])\n",
      "    newInts = map(int, valueNew[1:])\n",
      "    for old, new in zip(oldInts, newInts):\n",
      "        if old != new:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def compareLine5(oldHeader, newHeader):\n",
      "    #line 5\n",
      "    valueOld = re.split(\"\\s*\", oldHeader[5][:-1])\n",
      "    valueNew = re.split(\"\\s*\", newHeader[5][:-1])\n",
      "    assert len(valueOld) == len(valueNew)\n",
      "    for index in range(1, len(valueOld)):\n",
      "        if \"%.6g\" % float(valueOld[index]) != \"%.6g\" % float(valueNew[index]):\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n",
      "def compareLines6Plus(oldHeader, newHeader):\n",
      "    #lines 6, 12, 13\n",
      "    for line in [6, 12, 13]:\n",
      "        _, temp = re.split(\":\\s*\", oldHeader[line][:-1])\n",
      "        valuesOld = re.split(\"\\s*\", temp)\n",
      "\n",
      "        _, temp = re.split(\":\\s*\", newHeader[line][:-1])\n",
      "        valuesNew = re.split(\"\\s*\", temp)\n",
      "    \n",
      "        for index in range(len(valuesOld) - 1):\n",
      "            oldTriple = re.split(\",\", valuesOld[index][1:-1])\n",
      "            floatsOld = map(float, oldTriple)\n",
      "            \n",
      "            newTriple = re.split(\",\", valuesNew[index][1:-1])\n",
      "            floatsNew = map(float, newTriple)\n",
      "        \n",
      "            for count in range(3):\n",
      "                if not \"%.6g\" % floatsOld[index] == \"%.6g\" % floatsNew[index]:\n",
      "                    print line, \" \", index, \"%.6g\" % floatsOld[index]\n",
      "                    print line, \" \", index, \"%.7g\" % floatsNew[index]\n",
      "                    return False\n",
      "    return True\n",
      "    \n",
      "\n",
      "def compareGradientLines(oldHeader, newHeader):\n",
      "    #lines 16+\n",
      "    for line in range(16, headerLines_old):\n",
      "        _, temp = re.split(\"=\", oldHeader[line][:-1])\n",
      "        valueOld = re.split('\\s*', temp)\n",
      "        \n",
      "        _, temp = re.split(\"=\", newHeader[line][:-1])\n",
      "        valueNew = re.split('\\s*', temp)\n",
      "\n",
      "        floatsOld = map(float, valueOld)\n",
      "        floatsNew = map(float, valueNew)\n",
      "        # print \"floatsOld = %.6g, %.6g, %.6g\" % tuple(floatsOld)\n",
      "        # print \"floatsNew = %.6g, %.6g, %.6g\" % tuple(floatsNew)\n",
      "        # print \"unformatted = \", floatsNew\n",
      "        for index in range(3):\n",
      "            if not \"%.6g\" % floatsOld[index] == \"%.6g\" % floatsNew[index]:\n",
      "                print line, \" \", index, \"%.6g\" % floatsOld[index]\n",
      "                print line, \" \", index, \"%.7g\" % floatsNew[index]\n",
      "                return False\n",
      "    return True\n",
      "\n",
      "\n",
      "#xOld = valueOld[2][1:-1].split(\",\")\n",
      "#print \"%e, %e, %e\" % tuple(map(float, xOld))\n",
      "#xNew = valueNew[2][1:-1].split(\",\")\n",
      "#print \"%e, %e, %e\" % tuple(map(float, xNew))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print compareLine0(oldHeader, newHeader) and compareLine2(oldHeader, newHeader) and compareLine4(oldHeader, newHeader) and compareLine5(oldHeader, newHeader) and compareLines6Plus(oldHeader, newHeader) and compareGradientLines(oldHeader, newHeader)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Run ITK function as subprocess..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import *\n",
      "\n",
      "notEqual = []\n",
      "itkChecker = sp.Popen(['/ipldev/scratch/welchdm/bld/dwiCheck/dwicheck', oldpath, newpath], stdout=sp.PIPE, stderr=sp.PIPE)\n",
      "out, err = itkChecker.communicate()\n",
      "itkChecker.stdout.close()\n",
      "if (not err is None) or int(out) > 0:\n",
      "    print \"Error in comparison!\"\n",
      "    notEqual.append((oldpath, newpath, err))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in comparison!\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### SCRIPT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import keyring, re\n",
      "import subprocess as sp\n",
      "import psycopg2 as sql\n",
      "import ConfigParser as cp\n",
      "from warnings import warn\n",
      "import os\n",
      "\n",
      "class Database(object):\n",
      "    \"\"\" Connect to the Postgres database and prevent multiple user collisions\n",
      "        during simultaneous evaluations\n",
      "    \"\"\"\n",
      "    def __init__(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Class attributes needed for connecting to and interacting with the database\n",
      "\n",
      "        ------------------------\n",
      "        Arguments:\n",
      "        - `host`: The name of the host machine (default = 'localhost')\n",
      "        - `port`: The port number (default = 5432)\n",
      "        - `pguser`: The username to connect to the Postgres server with (default = 'postgres')\n",
      "        - `database`: The name of the database to connect to.  If omitted, it is the same as the `user`\n",
      "        - `password`: The password associated with the `user` on the Postgres server (default = 'postgres')\n",
      "        - `login`: The reviewer login ID (default = $USER)\n",
      "        - `arraySize`: The number of rows to return (default = 1)\n",
      "        - `imageTable`: The database table to query for records (default = None)\n",
      "        - `reviewTable`: The database table to update with reviews (default = None)\n",
      "        ------------------------\n",
      "\n",
      "        \"\"\"\n",
      "        validArgs = ('host', 'port', 'pguser', 'database', 'password',\n",
      "                     'login', 'arraySize', 'imageTable', 'reviewTable')\n",
      "        defaults = ('localhost', 5432, 'postgres', None, 'postgres',\n",
      "                    os.environ['USER'], 0, 'dwi_raw', 'dwi_raw_reviews')\n",
      "        self._testing = False\n",
      "        self._lines = None\n",
      "        self.rows = None\n",
      "        self.connection = None\n",
      "        self.cursor = None\n",
      "        self.reviewer_id = None\n",
      "        self.imageTable = None\n",
      "        self.reviewTable = None\n",
      "        argsList = list(args)\n",
      "        for key in validArgs:\n",
      "            if key in kwds.keys():\n",
      "                value = kwds[key]\n",
      "            elif len(argsList) != 0:\n",
      "                value =  argsList.pop(0)\n",
      "            else:\n",
      "                value = defaults[validArgs.index(key)]\n",
      "            setattr(self, key, value)\n",
      "        if self.database is None:\n",
      "            self.database = self.pguser\n",
      "        super(Database,self).__init__()\n",
      "        \n",
      "\n",
      "    def open(self):\n",
      "        \"\"\" Open the database and create a cursor \"\"\"\n",
      "        self.connection = sql.connect(host=self.host,\n",
      "                                      port=self.port,\n",
      "                                      database=self.database,\n",
      "                                      user=self.pguser,\n",
      "                                      password=self.password)\n",
      "        self.cursor = self.connection.cursor()\n",
      "        self.cursor.arraysize = self.arraySize\n",
      "\n",
      "\n",
      "    def close(self):\n",
      "        \"\"\" Close cursor and connection, setting values to None \"\"\"\n",
      "        self.cursor.close()\n",
      "        self.cursor = None\n",
      "        self.connection.close()\n",
      "        self.connection = None\n",
      "\n",
      "        \n",
      "    def getRecords(self, status='R', imageTable=None, **kwds):\n",
      "        \"\"\" Return a dictionary of rows where the number of rows == self.arraySize \"\"\"\n",
      "        if imageTable is None:\n",
      "            imageTable = self.imageTable\n",
      "        assert not imageTable is None, 'Table is not specified: value is \"None\"'\n",
      "        self.imageTable = imageTable\n",
      "        assert self.cursor is not None, 'The database is not open! Run Database.open()'\n",
      "        getRecord = \"SELECT * FROM {0} WHERE status = '{1}' ORDER BY priority\".format(imageTable, status)\n",
      "        try:\n",
      "            # logging.info(getRecord)\n",
      "            self.cursor.execute(getRecord)\n",
      "        except sql.ProgrammingError:\n",
      "            raise ValueError(\"The table '%s' does not exist in the database!\" % imageTable)\n",
      "        except sql.InternalError:\n",
      "            raise ValueError(\"The status '%s' is not a valid one\" % status)\n",
      "        except:\n",
      "            # logging.error()\n",
      "            print(\"SQL query: %s\" % getRecord)\n",
      "            raise\n",
      "        self.rows = self.cursor.fetchall()\n",
      "        if self.rows is None or self.rows == []:\n",
      "            # logging.warning()\n",
      "            print(\"No rows in table %s with status %s were found!\" % (imageTable, status))\n",
      "\n",
      "\n",
      "\n",
      "    def readRecords(self, **kwds):\n",
      "        \"\"\" Find a given number of records with status == 'R' and return the records in a dictionary-like object \"\"\"\n",
      "        self.open()\n",
      "        try:\n",
      "            if self._testing and 'imageTable' in kwds.keys():\n",
      "                self.imageTable = kwds['imageTable']\n",
      "            self.getRecords(**kwds)\n",
      "        finally:\n",
      "            self.close()\n",
      "        return self.rows\n",
      "\n",
      "\n",
      "def compareLine0(oldHeader, newHeader):\n",
      "    #line 0\n",
      "    valueOld = re.search(r'NRRD(?P<val>[0-9]{4})$', oldHeader[0]).group('val')\n",
      "    valueNew = re.search(r'NRRD(?P<val>[0-9]{4})$', newHeader[0]).group('val')\n",
      "    if valueOld != valueNew:\n",
      "        return False\n",
      "    return True\n",
      "\n",
      "\n",
      "def compareLine2(oldHeader, newHeader):\n",
      "    #line 2\n",
      "    _, valueOld = re.split(\"\\s*\", oldHeader[2][:-1])\n",
      "    _, valueNew = re.split(\"\\s*\", newHeader[2][:-1])\n",
      "    if int(valueOld) != int(valueNew):\n",
      "        return False\n",
      "    return True\n",
      "\n",
      "\n",
      "def compareLine4(oldHeader, newHeader):\n",
      "    #line 4\n",
      "    valueOld = re.split(\"\\s*\", oldHeader[4][:-1])\n",
      "    valueNew = re.split(\"\\s*\", newHeader[4][:-1])\n",
      "    oldInts = map(int, valueOld[1:])\n",
      "    newInts = map(int, valueNew[1:])\n",
      "    for old, new in zip(oldInts, newInts):\n",
      "        if old != new:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def compareLine5(oldHeader, newHeader):\n",
      "    #line 5\n",
      "    valueOld = re.split(\"\\s*\", oldHeader[5][:-1])\n",
      "    valueNew = re.split(\"\\s*\", newHeader[5][:-1])\n",
      "    assert len(valueOld) == len(valueNew)\n",
      "    for index in range(1, len(valueOld)):\n",
      "        if \"%.6g\" % float(valueOld[index]) != \"%.6g\" % float(valueNew[index]):\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n",
      "def compareLines6Plus(oldHeader, newHeader):\n",
      "    #lines 6, 12, 13\n",
      "    for line in [6, 12, 13]:\n",
      "        _, temp = re.split(\":\\s*\", oldHeader[line][:-1])\n",
      "        valuesOld = re.split(\"\\s*\", temp)\n",
      "\n",
      "        _, temp = re.split(\":\\s*\", newHeader[line][:-1])\n",
      "        valuesNew = re.split(\"\\s*\", temp)\n",
      "    \n",
      "        for index in range(len(valuesOld) - 1):\n",
      "            oldTriple = re.split(\",\", valuesOld[index][1:-1])\n",
      "            floatsOld = map(float, oldTriple)\n",
      "            \n",
      "            newTriple = re.split(\",\", valuesNew[index][1:-1])\n",
      "            floatsNew = map(float, newTriple)\n",
      "        \n",
      "            for count in range(3):\n",
      "                if not \"%.6g\" % floatsOld[index] == \"%.6g\" % floatsNew[index]:\n",
      "                    print line, \" \", index, \"%.6g\" % floatsOld[index]\n",
      "                    print line, \" \", index, \"%.7g\" % floatsNew[index]\n",
      "                    return False\n",
      "    return True\n",
      "    \n",
      "\n",
      "def compareGradientLines(oldHeader, newHeader):\n",
      "    #lines 16+\n",
      "    for line in range(16, headerLines_old):\n",
      "        _, temp = re.split(\"=\", oldHeader[line][:-1])\n",
      "        valueOld = re.split('\\s*', temp)\n",
      "        \n",
      "        _, temp = re.split(\"=\", newHeader[line][:-1])\n",
      "        valueNew = re.split('\\s*', temp)\n",
      "\n",
      "        floatsOld = map(float, valueOld)\n",
      "        floatsNew = map(float, valueNew)\n",
      "        for index in range(3):\n",
      "            if not \"%.6g\" % floatsOld[index] == \"%.6g\" % floatsNew[index]:\n",
      "                print line, \" \", index, \"%.6g\" % floatsOld[index]\n",
      "                print line, \" \", index, \"%.7g\" % floatsNew[index]\n",
      "                return False\n",
      "    return True\n",
      "\n",
      "\n",
      "def dwiPrecisionCheck(*args, **kwds):\n",
      "    notEqual = []\n",
      "    old_root = '/paulsen/20130131_BACKUP_TRUNCATED_DWI'\n",
      "    db = Database(host='psych-db.psychiatry.uiowa.edu', database='AutoWorkUp', pguser='autoworkup', password=keyring.get_password('autoworkup', user))\n",
      "    reviewedRecords = db.readRecords(status='R', imageTable='dwi_raw')\n",
      "    \n",
      "    for record_id, root, site, subject, session, dirname, filename, status, priority, _ in reviewedRecords:\n",
      "        if site[:4] == 'HDNI':\n",
      "            pass\n",
      "        fullname = \"_\".join([subject, session, filename + \".nrrd\"])\n",
      "        \n",
      "        oldpath = os.path.join(old_root, site, subject, session, dirname, fullname)\n",
      "        prefix, numbers = filename.split('-')\n",
      "        oldgradient, series = numbers.split('_')\n",
      "            \n",
      "        newpath = os.path.join(root, site, subject, session, dirname, fullname)\n",
      "            \n",
      "        if not os.path.exists(newpath):\n",
      "            # DWI gradient number may have been incremented\n",
      "            newgradient = str(int(oldgradient) + 1)\n",
      "            newfilename = prefix + \"-\" + newgradient + \"_\" + series\n",
      "            newfullname = \"_\".join([subject, session, newfilename + \".nrrd\"])\n",
      "            newpath = os.path.join(root, site, subject, session, dirname, )\n",
      "            print \"\"\n",
      "            print \"Gradient count is increased! %s\" % newfullname\n",
      "        else:\n",
      "            newgradient = oldgradient\n",
      "\n",
      "        # number of 'standard' lines in header\n",
      "        headerLines_old = 16 + int(oldgradient)\n",
      "        headerLines_new = 16 + int(newgradient)\n",
      "        \n",
      "        #HACK\n",
      "        #newpath = \"/paulsen/MRx/PHD_048/2408/16520/ANONRAW/2408_16520_DWI-34_801.nrrd\"\n",
      "        #headerLines_new = 34\n",
      "        #oldpath = \"/paulsen/20130131_BACKUP_TRUNCATED_DWI/PHD_048/2408/16520/ANONRAW/2408_16520_DWI-33_801.nrrd\"\n",
      "        #headerLines_old = 33\n",
      "\n",
      "        newpath = \"/paulsen/MRx/PHD_024/2576/27032/ANONRAW/2576_27032_DWI-65_5.nrrd\"\n",
      "        headerLines_new = 65\n",
      "        oldpath = \"/paulsen/20130131_BACKUP_TRUNCATED_DWI/PHD_024/2576/27032/ANONRAW/2576_27032_DWI-65_5.nrrd\"\n",
      "        headerLines_old = 65\n",
      "        #END HACK\n",
      "        \n",
      "        oldHeader = []\n",
      "        newHeader = []\n",
      "        if os.path.exists(oldpath) and os.path.exists(newpath):\n",
      "            with open(oldpath, 'r') as old:\n",
      "                for count in range(headerLines_old):\n",
      "                    oldHeader.append(old.readline())\n",
      "        \n",
      "            with open(newpath, 'r') as new:\n",
      "                for count in range(headerLines_new):\n",
      "                    newHeader.append(new.readline())\n",
      "        else:\n",
      "            # print oldpath\n",
      "            # print newpath\n",
      "            pass\n",
      "        \n",
      "        itkChecker = sp.Popen(['/ipldev/scratch/welchdm/bld/dwiCheck/dwicheck', oldpath, newpath], stdout=sp.PIPE, stderr=sp.PIPE)\n",
      "        out, err = itkChecker.communicate()\n",
      "        itkChecker.stdout.close()\n",
      "        if (not err is None) or int(out) > 0:\n",
      "            print \"Error in comparison: %s\" % newpath\n",
      "            notEqual.append((oldpath, newpath, err))\n",
      "        else:\n",
      "            if compareLine0(oldHeader, newHeader) and \\\n",
      "              compareLine2(oldHeader, newHeader) and \\\n",
      "              compareLine4(oldHeader, newHeader) and \\\n",
      "              compareLine5(oldHeader, newHeader) and \\\n",
      "              compareLines6Plus(oldHeader, newHeader) and \\\n",
      "              compareGradientLines(oldHeader, newHeader):\n",
      "                pass\n",
      "            else:\n",
      "                err = \"Headers not equal!\"\n",
      "                notEqual.append((oldpath, newpath, err))\n",
      "\n",
      "        ### HACK\n",
      "        break\n",
      "        ### END HACK\n",
      "    return notEqual\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    import sys\n",
      "    notEqual = dwiPrecisionCheck(sys.argv[:])\n",
      "    with open('notEqual.txt', 'w') as out:\n",
      "        out.write(notEqual)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "unexpected indent (<ipython-input-30-a5e119ab9b2b>, line 190)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### SCRATCH"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    import re\n",
      "\n",
      "    regex = '^[\\w_]+[0-9]{4}:=(?P<xval>[-\\.e\\d]+)[\\s]*(?P<yval>[-\\.e\\d]+)[\\s]*(?P<zval>[-\\.e\\d]+$)'\n",
      "    pattern = re.compile(regex)\n",
      "    for line in range(16):\n",
      "        if oldHeader[line] == newHeader[line]:\n",
      "            print \"Not equal?\"\n",
      "            print(r'%s' % oldHeader[line])\n",
      "            print unicode(newHeader[line])\n",
      "            print \"\"\n",
      "    \n",
      "    #     old_result = pattern.search(oldHeader[line])\n",
      "    #     new_result = pattern.search(newHeader[line])\n",
      "    #     if old_result is None:\n",
      "    #         print line\n",
      "    #         print oldHeader[line]\n",
      "    #     else:\n",
      "    #         for key in ['xval', 'yval', 'zval']:\n",
      "    #             #if float(old_result.group(key)) != float(new_result.group(key)):\n",
      "    #             # print line\n",
      "    #             print old_result.group(key) + ' vs ' + new_result.group(key)\n",
      "    #         print \"\"\n",
      "    # \"\"\"\n",
      "    # \"\"\"\n",
      "    # for line in range(16):\n",
      "    #     if oldHeader[line] != newHeader[line]:\n",
      "    #         print oldHeader[line]\n",
      "    #         print newHeader[line]\n",
      "    #         print \"\"\n",
      "    # \"\"\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    import re\n",
      "    \n",
      "    regex = '^[\\w_]+[0-9]{4}:=(?P<xval>[-\\.e\\d]+)[\\s]*(?P<yval>[-\\.e\\d]+)[\\s]*(?P<zval>[-\\.e\\d]+$)'\n",
      "    pattern = re.compile(regex)\n",
      "    for line in range(16, len(oldHeader)):\n",
      "        #print oldHeader[line]\n",
      "        #print newHeader[line]\n",
      "        old_result = pattern.search(oldHeader[line])\n",
      "        new_result = pattern.search(newHeader[line])\n",
      "        if old_result is None:\n",
      "            print line\n",
      "            print oldHeader[line]\n",
      "        else:\n",
      "            for key in ['xval', 'yval', 'zval']:\n",
      "                #if float(old_result.group(key)) != float(new_result.group(key)):\n",
      "                # print line\n",
      "                print old_result.group(key) + ' vs ' + new_result.group(key)\n",
      "            print \"\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}